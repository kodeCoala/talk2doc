{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b1124100-d365-4627-81da-2bafc22384bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.cohere import Cohere\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "134789ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows nested access to event loop\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "402ba272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/msrivas/hack/ai/talk2doc/docs\n"
     ]
    }
   ],
   "source": [
    "# cohere API key\n",
    "API_KEY = os.environ.get(\"API_KEY\")\n",
    "# input doc directory\n",
    "input_dir_name = os.environ.get(\"DIR\")\n",
    "print(input_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f62f3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = SimpleDirectoryReader(\n",
    "  input_dir=input_dir_name,\n",
    "  required_exts=['.pdf'],\n",
    "  recursive=True\n",
    ")\n",
    "\n",
    "docs = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "136ac929",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = CohereEmbedding(\n",
    "  cohere_api_key=API_KEY,\n",
    "  model_name='embed-english-v3.0',\n",
    "  input_type='search_query'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ceebfd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# Create vecotr store and upload indexed data\n",
    "Settings.embed_model = embed_model\n",
    "index = VectorStoreIndex.from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45912a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.cohere import Cohere\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "# create query engine\n",
    "cohere_rerank = CohereRerank(api_key=API_KEY, top_n=2)\n",
    "Settings.llm = Cohere(api_key=API_KEY, model='command-r-plus')\n",
    "query_engine = index.as_query_engine(node_postprocessors=[cohere_rerank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1907cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "qa_prompt_tmpl_str = (\n",
    "  \"Context information is below.\\n\"\n",
    "  \"-------------------------\\n\"\n",
    "  \"{context_str}\\n\"\n",
    "  \"Given the context information above I want you\\n\"\n",
    "  \"to think step by step to answer the query in a crisp \\n\"\n",
    "  \"manner, incase you don't knkow the answer say \\n\"\n",
    "  \"'I don't know!'. \\n\"\n",
    "  \"Query: {query_str}\\n\"\n",
    "  \"Answer: \"\n",
    ")\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
    "query_engine.update_prompts({\"response_synthesizer:text_qa_template\": qa_prompt_tmpl})\n",
    "question = 'explain do VAE\\'s work in detail. Explain in steps how one would go about building a VAE'\n",
    "response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf478f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "wrapped_text = textwrap.fill(str(response), width=80)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f8bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talk2doc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
