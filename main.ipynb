{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b1124100-d365-4627-81da-2bafc22384bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.cohere import Cohere\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "134789ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows nested access to event loop\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "402ba272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/msrivas/hack/ai/talk2doc/docs\n"
     ]
    }
   ],
   "source": [
    "# cohere API key\n",
    "API_KEY = os.environ.get(\"API_KEY\")\n",
    "# input doc directory\n",
    "input_dir_name = os.environ.get(\"DIR\")\n",
    "print(input_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f62f3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = SimpleDirectoryReader(\n",
    "  input_dir=input_dir_name,\n",
    "  required_exts=['.pdf'],\n",
    "  recursive=True\n",
    ")\n",
    "\n",
    "docs = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "136ac929",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = CohereEmbedding(\n",
    "  cohere_api_key=API_KEY,\n",
    "  model_name='embed-english-v3.0',\n",
    "  input_type='search_query'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ceebfd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# Create vecotr store and upload indexed data\n",
    "Settings.embed_model = embed_model\n",
    "index = VectorStoreIndex.from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45912a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.cohere import Cohere\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "# create query engine\n",
    "cohere_rerank = CohereRerank(api_key=API_KEY, top_n=2)\n",
    "Settings.llm = Cohere(api_key=API_KEY, model='command-r-plus')\n",
    "query_engine = index.as_query_engine(node_postprocessors=[cohere_rerank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1907cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "qa_prompt_tmpl_str = (\n",
    "  \"Context information is below.\\n\"\n",
    "  \"-------------------------\\n\"\n",
    "  \"{context_str}\\n\"\n",
    "  \"Given the context information above I want you\\n\"\n",
    "  \"to think step by step to answer the query in a crisp \\n\"\n",
    "  \"manner, incase you don't knkow the answer say \\n\"\n",
    "  \"'I don't know!'. \\n\"\n",
    "  \"Query: {query_str}\\n\"\n",
    "  \"Answer: \"\n",
    ")\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
    "query_engine.update_prompts({\"response_synthesizer:text_qa_template\": qa_prompt_tmpl})\n",
    "question = 'explain do VAE\\'s work in detail. Explain in steps how one would go about building a VAE'\n",
    "response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cf478f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can provide a high-level explanation of how VAEs work and a step-by-step guide\n",
      "on building one.   **How VAEs Work:**  VAEs, or Variational Autoencoders, are a\n",
      "type of generative machine learning model used for unsupervised learning tasks,\n",
      "particularly in generating new data similar to the training data and extracting\n",
      "valuable insights from high-dimensional data.   Here's a simplified breakdown of\n",
      "how VAEs work:   1. **Encoding:** The VAE first encodes the input data into a\n",
      "latent space, typically of lower dimensionality, using a neural network called\n",
      "the encoder. This latent space represents a probabilistic distribution of the\n",
      "input data, often assumed to follow a Gaussian distribution.   2. **Sampling:**\n",
      "From this latent space, the VAE samples points, introducing randomness into the\n",
      "model. This step allows the VAE to generate new data points that are similar to,\n",
      "but not exactly the same as, the training data.   3. **Decoding:** The sampled\n",
      "points are then passed through another neural network, the decoder, which maps\n",
      "them back to the original input space. The decoder tries to reconstruct the\n",
      "original input data from the latent representation.   4. **Optimization:** The\n",
      "VAE is trained by optimizing two objectives:      - **Reconstruction Loss:**\n",
      "This measures how well the VAE can reconstruct the input data and is typically\n",
      "measured using a distance metric like mean squared error or cross-entropy loss.\n",
      "- **Kullback-Leibler (KL) Divergence:** This term measures the difference\n",
      "between the latent space distribution and the prior distribution, which is often\n",
      "assumed to be a standard Gaussian. This term encourages the latent space to\n",
      "follow a simple distribution, making the generation of new data easier.\n",
      "**Building a VAE:**  Here's a step-by-step guide on how one might go about\n",
      "building a basic VAE:   1. **Define the Data:** Start by understanding the data\n",
      "you want to model. Ensure it is suitable for unsupervised learning and that you\n",
      "have a sufficient amount of it.   2. **Choose a Network Architecture:** Decide\n",
      "on the structure of your encoder and decoder networks. The encoder should map\n",
      "the input data to a latent space, and the decoder should map the latent space\n",
      "back to the original input space.   3. **Define the Loss Function:** Implement\n",
      "the loss function, which consists of the reconstruction loss and the KL\n",
      "divergence term. You may also include additional regularization terms depending\n",
      "on your specific task.   4. **Train the Model:** Use your chosen optimization\n",
      "algorithm (e.g., stochastic gradient descent) to update the weights of the\n",
      "encoder and decoder networks to minimize the loss function.   5. **Evaluate and\n",
      "Tweak:** After training, evaluate the model's performance using appropriate\n",
      "metrics. You may need to adjust the network architecture, hyperparameters, or\n",
      "training data to improve performance.   6. **Generate New Data:** Once you're\n",
      "satisfied with your model's performance, you can use it to generate new data by\n",
      "sampling from the latent space and passing the samples through the decoder.   7.\n",
      "**Explore Advanced Techniques:** Depending on your specific task, you may want\n",
      "to explore more advanced VAE techniques, such as using multiple latent\n",
      "variables, incorporating domain knowledge, or applying VAE to time series data.\n",
      "Remember that building a VAE often involves experimentation and iteration to\n",
      "find the right architecture and hyperparameters for your specific data and task.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "wrapped_text = textwrap.fill(str(response), width=80)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f8bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talk2doc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
